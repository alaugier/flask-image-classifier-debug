#!/usr/bin/env python3
"""
Analyseur de performances pour identifier les goulots d'√©tranglement.
Usage: python scripts/analyze_performance.py
"""

import sqlite3
import os
from datetime import datetime
import statistics

def analyze_performance_issues(conn):
    """Analyse d√©taill√©e des probl√®mes de performance."""
    cursor = conn.cursor()
    
    print("üîç DIAGNOSTIC DE PERFORMANCE")
    print("=" * 50)
    
    # Analyse des endpoint les plus lents
    query = """
    SELECT e.name as endpoint,
           COUNT(r.id) as requests,
           AVG(r.duration) as avg_duration,
           MAX(r.duration) as max_duration,
           MIN(r.duration) as min_duration
    FROM fmd_Request r
    JOIN fmd_Endpoint e ON r.endpoint_id = e.id
    GROUP BY e.name
    HAVING COUNT(r.id) > 1
    ORDER BY avg_duration DESC;
    """
    
    cursor.execute(query)
    results = cursor.fetchall()
    
    print("üìä Performances par endpoint:")
    print(f"{'Endpoint':<20} {'Requ√™tes':<10} {'Moyenne':<12} {'Max':<12} {'Diagnostic'}")
    print("-" * 80)
    
    for row in results:
        avg_ms = row['avg_duration'] * 1000
        max_ms = row['max_duration'] * 1000
        
        # Diagnostic automatique
        if avg_ms > 5000:
            diagnostic = "üö® TR√àS LENT"
        elif avg_ms > 2000:
            diagnostic = "‚ö†Ô∏è LENT"  
        elif avg_ms > 500:
            diagnostic = "üü° MOYEN"
        else:
            diagnostic = "‚úÖ RAPIDE"
            
        print(f"{row['endpoint']:<20} {row['requests']:<10} "
              f"{avg_ms:<12.0f}ms {max_ms:<12.0f}ms {diagnostic}")

def suggest_optimizations():
    """Suggestions d'optimisation bas√©es sur l'analyse."""
    print("\nüí° SUGGESTIONS D'OPTIMISATION")
    print("=" * 40)
    
    suggestions = [
        "1. PR√âDICTION LENTE (4-7 secondes):",
        "   - V√©rifier si le mod√®le utilise le GPU",
        "   - Optimiser le preprocessing (vectorisation)",
        "   - Consid√©rer un mod√®le plus l√©ger",
        "   - Impl√©menter un cache pour images similaires",
        "",
        "2. FEEDBACK LENT (20-47 secondes):",
        "   - V√©rifier la connexion MongoDB Atlas",
        "   - Optimiser les index MongoDB", 
        "   - R√©duire la taille des donn√©es stock√©es",
        "   - Passer en asynchrone pour l'√©criture DB",
        "",
        "3. RATE LIMITING:",
        "   - Le d√©corateur @rate_limit(10) cause des d√©lais artificiels",
        "   - Consid√©rer l'augmenter ou le supprimer en dev",
        "",
        "4. MONITORING:",
        "   - Flask-MonitoringDashboard ajoute une overhead",
        "   - R√©duire MONITOR_LEVEL en production",
        "",
        "5. CODE OPTIMIZATIONS:",
        "   - Lazy loading du mod√®le",
        "   - Connection pooling pour MongoDB",
        "   - Compression des images avant stockage"
    ]
    
    for suggestion in suggestions:
        print(suggestion)

def analyze_rate_limiting_impact(conn):
    """Analyse l'impact du rate limiting."""
    cursor = conn.cursor()
    
    print("\nüö¶ ANALYSE DU RATE LIMITING")
    print("=" * 35)
    
    # Chercher les patterns de d√©lais fixes (indicateur de rate limiting)
    query = """
    SELECT e.name,
           r.duration,
           r.time_requested,
           LAG(r.time_requested) OVER (PARTITION BY e.name ORDER BY r.time_requested) as prev_request
    FROM fmd_Request r
    JOIN fmd_Endpoint e ON r.endpoint_id = e.id
    WHERE e.name = 'predict'
    ORDER BY r.time_requested DESC
    LIMIT 10;
    """
    
    cursor.execute(query)
    results = cursor.fetchall()
    
    intervals = []
    for i, row in enumerate(results[1:], 1):  # Skip first row (no previous)
        if row['prev_request']:
            curr_time = datetime.fromisoformat(row['time_requested'].replace('Z', '+00:00'))
            prev_time = datetime.fromisoformat(row['prev_request'].replace('Z', '+00:00'))
            interval = (curr_time - prev_time).total_seconds()
            intervals.append(interval)
    
    if intervals:
        avg_interval = statistics.mean(intervals)
        print(f"Intervalle moyen entre pr√©dictions: {avg_interval:.1f}s")
        
        # Le rate limit √† 10/minute = 6s minimum entre requ√™tes
        if avg_interval >= 5.5:  # Avec marge d'erreur
            print("‚ö†Ô∏è Rate limiting d√©tect√© - consid√©rez l'ajuster pour les tests")
        else:
            print("‚úÖ Pas de rate limiting apparent")

def main():
    """Fonction principale d'analyse."""
    db_path = os.path.join('app', 'monitoring_dashboard.db')
    if not os.path.exists(db_path):
        print(f"‚ùå Base de donn√©es non trouv√©e: {db_path}")
        return
    
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    
    try:
        analyze_performance_issues(conn)
        analyze_rate_limiting_impact(conn)
        suggest_optimizations()
        
        print("\nüéØ ACTIONS PRIORITAIRES:")
        print("1. Retirer @rate_limit pour les tests de performance")
        print("2. V√©rifier la latence r√©seau vers MongoDB Atlas")
        print("3. Profiler le temps de pr√©diction du mod√®le")
        print("4. R√©duire MONITOR_LEVEL=1 en production")
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
    finally:
        conn.close()

if __name__ == "__main__":
    main()